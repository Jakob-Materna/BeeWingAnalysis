{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25e66cb6-406f-4cf4-9bae-1e56eb4bdbd2",
   "metadata": {},
   "source": [
    "### 1-3-ScansWingAlignment.ipynb\n",
    "\n",
    "Identifies the background using segment-anything and finds the smallest rectangle possible around the wing to determine the orientation and measure the height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4df48c1-793d-451f-a577-c2f57aead518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import glob\n",
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "from scipy.ndimage import label, sum as ndimage_sum\n",
    "\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c09f8c33-04c3-41dc-9e4d-64ac6a977e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data directories\n",
    "data_dir = Path(\"/mnt/g/Projects/Master/Data/\")\n",
    "\n",
    "input_dir = data_dir / \"Processed\" / \"WingScans\" / \"2-ScansManualImprovements\" \n",
    "output_dir = data_dir / \"Processed\" / \"WingScans\" / \"3-ScanWingsAligned\" \n",
    "output_wing_dir = output_dir / \"Wings\"\n",
    "\n",
    "# Sam checkpoint path\n",
    "sam2_checkpoint = \"/home/wsl/bin/segment-anything-2/checkpoints/sam2_hiera_tiny.pt\"\n",
    "model_cfg = \"sam2_hiera_t.yaml\"\n",
    "\n",
    "PIXELS_PER_MM = 3359/53.4\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dac76f7-864b-4632-9f2b-9b80a71d29ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_points_near_border(points, contour, border_dist_threshold):\n",
    "    \"\"\"\n",
    "    Filters out points too close to the edge of the wing to improve segment anything results.\n",
    "    \"\"\"\n",
    "    filtered_points = []\n",
    "\n",
    "    # Iterate over all points\n",
    "    for point in points:\n",
    "        # Check the distance of the point to the contour\n",
    "        dist_to_contour = cv2.pointPolygonTest(contour, (point[0], point[1]), True)\n",
    "        \n",
    "        # Keep the point if it's farther from the border than the threshold\n",
    "        if dist_to_contour >= border_dist_threshold:\n",
    "            filtered_points.append(point)\n",
    "    \n",
    "    return np.array(filtered_points)\n",
    "\n",
    "    \n",
    "def find_black_area(image, window_size):\n",
    "    \"\"\"\n",
    "    Identifies the coordinates of the black area at the base of the wing. \n",
    "    \"\"\"\n",
    "    h, w = image.shape\n",
    "    max_density = -1\n",
    "    best_coords = (0, 0)\n",
    "\n",
    "    # Slide the window over the image\n",
    "    for y in range(0, h - window_size[1] + 1, 1):\n",
    "        for x in range(0, w - window_size[0] + 1, 1):\n",
    "            # Extract the window from the image\n",
    "            window = image[y:y + window_size[1], x:x + window_size[0]]\n",
    "\n",
    "            # Count the number of black pixels (assuming black pixels are 0)\n",
    "            black_pixel_count = np.sum(window == 0)\n",
    "\n",
    "            # Track the window with the maximum number of black pixels\n",
    "            if black_pixel_count > max_density:\n",
    "                max_density = black_pixel_count\n",
    "                best_coords = (x, y)\n",
    "\n",
    "    return best_coords, max_density\n",
    "        \n",
    "\n",
    "def postprocess_mask(mask):\n",
    "    \"\"\"\n",
    "    Improves the output created by segment anything by selecting the best mask and filling holes.\n",
    "    \"\"\"\n",
    "    labeled_mask, num_features = label(mask)\n",
    "    if num_features == 0: \n",
    "        return mask\n",
    "    component_sizes = ndimage_sum(mask, labeled_mask, range(1, num_features + 1))\n",
    "    largest_component_label = np.argmax(component_sizes) + 1 \n",
    "    largest_component_mask = labeled_mask == largest_component_label\n",
    "\n",
    "    largest_component_mask = np.squeeze(largest_component_mask)\n",
    "    filled_image = binary_fill_holes(largest_component_mask)\n",
    "\n",
    "    clean_mask = binary_fill_holes(largest_component_mask)\n",
    "    if DEBUG:\n",
    "        # Display original and filled images\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "        axes[0].imshow(largest_component_mask, cmap=\"gray\")\n",
    "        axes[0].set_title(\"largest_component_mask\")\n",
    "        axes[0].axis(\"off\")\n",
    "        axes[1].imshow(clean_mask, cmap=\"gray\")\n",
    "        axes[1].set_title(\"clean_mask\")\n",
    "        axes[1].axis(\"off\")\n",
    "        plt.show()\n",
    "    return clean_mask\n",
    "\n",
    "\n",
    "def remove_background(wing):\n",
    "    \"\"\"\n",
    "    Uses segment anything to create a wing mask and removes everything outside the mask.\n",
    "    \"\"\"\n",
    "    expanded_image = wing\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(expanded_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply thresholding to get a binary image\n",
    "    _, thresh = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Invert the binary image\n",
    "    inv_thresh = cv2.bitwise_not(thresh)\n",
    "    \n",
    "    # Find contour\n",
    "    contours, _ = cv2.findContours(inv_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    large_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > 5000]\n",
    "    \n",
    "    # Find the largest contour based on area\n",
    "    contour = max(large_contours, key=cv2.contourArea)\n",
    "    \n",
    "    # Draw contours on the image for visualization\n",
    "    wing_contour_image = expanded_image.copy()\n",
    "    cv2.drawContours(wing_contour_image, large_contours, -1, (0, 0, 255), 5)\n",
    "\n",
    "    if DEBUG:\n",
    "        # Show image\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.imshow(cv2.cvtColor(wing_contour_image, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    # Get bounding box of the contour\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    \n",
    "    # Create a dense grid of points within the bounding box\n",
    "    distance = 100  \n",
    "    height, width, channels = expanded_image.shape  \n",
    "    \n",
    "    # Create x and y coordinates\n",
    "    x_coords = np.arange(0, width, distance)\n",
    "    y_coords = np.arange(0, height, distance)\n",
    "    \n",
    "    # Create a meshgrid from the x and y coordinates\n",
    "    grid_x, grid_y = np.meshgrid(x_coords, y_coords)\n",
    "    \n",
    "    # Stack the x and y coordinates into a single array of points\n",
    "    grid_points = np.vstack([grid_x.ravel(), grid_y.ravel()]).T\n",
    "    \n",
    "    # Convert the NumPy array to a list of tuples with standard integers\n",
    "    grid_points = [(int(x), int(y)) for x, y in grid_points]\n",
    "    \n",
    "    inside_points = []\n",
    "    \n",
    "    # Check if points are inside the contour\n",
    "    for point in grid_points:\n",
    "        if cv2.pointPolygonTest(contour, (point[0], point[1]), False) >= 0:\n",
    "            inside_points.append(point)\n",
    "    \n",
    "    filtered_points = remove_points_near_border(inside_points, contour, 25)\n",
    "    \n",
    "    window_size = (5, 5)\n",
    "    best_coords, max_density = find_black_area(gray, window_size)\n",
    "    filtered_points = np.vstack([filtered_points, best_coords])\n",
    "\n",
    "    if DEBUG:\n",
    "        # Plot the contour and the selected points\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.imshow(cv2.cvtColor(wing_contour_image, cv2.COLOR_BGR2RGB))\n",
    "        plt.scatter(best_coords[0], best_coords[1], c=\"green\", s=10)\n",
    "        plt.scatter(filtered_points[:, 0], filtered_points[:, 1], c=\"red\", s=5)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    # Sam background removal\n",
    "    # Convert the points list to a numpy array\n",
    "    image_points = np.array(filtered_points)\n",
    "    image_labels = np.array([1] * len(filtered_points))\n",
    "    \n",
    "    predictor.set_image(expanded_image)\n",
    "    \n",
    "    mask, score, _ = predictor.predict(\n",
    "        point_coords=image_points,\n",
    "        point_labels=image_labels,\n",
    "        multimask_output=False,\n",
    "    )\n",
    "    sorted_ind = np.argsort(score)[::-1]\n",
    "    mask = mask[sorted_ind]\n",
    "    score = score[sorted_ind]\n",
    "\n",
    "    # Improve mask quality\n",
    "    mask = postprocess_mask(mask)\n",
    "    \n",
    "    # Remove extra dimension\n",
    "    mask = mask.squeeze()\n",
    "    \n",
    "    # Create a white image of the same size as the original image\n",
    "    white_image = np.ones_like(expanded_image) * 255\n",
    "    \n",
    "    # Apply the mask to each channel (no extra dimension added)\n",
    "    wing_image = np.where(mask[:, :, None], expanded_image, white_image)\n",
    "\n",
    "    if DEBUG:\n",
    "        # Show image\n",
    "        plt.figure(figsize=(20, 20))\n",
    "        plt.imshow(cv2.cvtColor(wing_image, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    return wing_image\n",
    "\n",
    "def crop_wing(wing_image):\n",
    "    \"\"\"\n",
    "    This main function finds an initial wing contour which is then improved with segment anything to remove the background. \n",
    "    \"\"\"\n",
    "    expanded_image = cv2.copyMakeBorder(wing_image, 1000, 1000, 1000, 1000, cv2.BORDER_CONSTANT, value=[255, 255, 255])\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(expanded_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply thresholding to get a binary image\n",
    "    _, thresh = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Invert the binary image\n",
    "    inv_thresh = cv2.bitwise_not(thresh)\n",
    "\n",
    "    # Find contour\n",
    "    contours, _ = cv2.findContours(inv_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    large_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > 5000]\n",
    "\n",
    "    # Find the largest contour based on area\n",
    "    contour = max(large_contours, key=cv2.contourArea)\n",
    "    \n",
    "    # Draw contours on the image for visualization\n",
    "    wing_contour_image = expanded_image.copy()\n",
    "    cv2.drawContours(wing_contour_image, large_contours, -1, (0, 0, 255), 5)\n",
    "\n",
    "    # Get the minimum area rectangle\n",
    "    rect = cv2.minAreaRect(contour)\n",
    "    \n",
    "    # Get the four points of the rectangle\n",
    "    box = cv2.boxPoints(rect)\n",
    "    \n",
    "    # Convert the points to integers\n",
    "    box = np.intp(box)\n",
    "    \n",
    "    # Draw the rotated rectangle\n",
    "    contour_image = expanded_image.copy()\n",
    "    cv2.drawContours(contour_image, [box], 0, (0, 0, 255), 5)\n",
    "    \n",
    "    # Get the rectangle's center, size (width, height), and angle\n",
    "    box_center, box_size, angle = rect\n",
    "    \n",
    "    # Ensure width is the longest side (width > height)\n",
    "    width, height = box_size\n",
    "    if height > width:\n",
    "        width, height = height, width\n",
    "        angle -= 90  # Rotate to make the longest side horizontal\n",
    "    \n",
    "    # Get the rotation matrix to rotate the image around the rectangle's center\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(box_center, angle, 1.0)\n",
    "    \n",
    "    # Rotate the entire image\n",
    "    rotated_image = cv2.warpAffine(expanded_image, rotation_matrix, (expanded_image.shape[1], expanded_image.shape[0]))\n",
    "    \n",
    "    # Convert the center and size to integers\n",
    "    box_center = (int(box_center[0]), int(box_center[1]))\n",
    "    width, height = int(width), int(height)\n",
    "    \n",
    "    # Crop the aligned rectangle from the rotated image\n",
    "    cropped_image = cv2.getRectSubPix(rotated_image, (width+20, height+20), box_center)\n",
    "\n",
    "    return(cropped_image, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bb33746-4270-4e7a-9fd3-4e3ae990e8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|████████████████████████████████████████████████████████████████████████████████████| 4380/4380 [5:11:25<00:00,  4.27s/it]\n"
     ]
    }
   ],
   "source": [
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# select the device for computation\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"using device: {device}\")\n",
    "\n",
    "# Load sam model\n",
    "sam2_model = build_sam2(model_cfg, sam2_checkpoint, device=device)\n",
    "predictor = SAM2ImagePredictor(sam2_model)\n",
    "    \n",
    "try:\n",
    "    # Ensure the input directory exists\n",
    "    if not os.path.exists(input_dir):\n",
    "        raise FileNotFoundError(f\"Input directory '{input_dir}' was not found.\")\n",
    "    \n",
    "    # Create the output directories\n",
    "    if os.path.exists(output_wing_dir):\n",
    "        print(\"WARNING: Output directory already exists.\") \n",
    "    os.makedirs(output_wing_dir, exist_ok=True)\n",
    "    \n",
    "    # Create or open a CSV file and write the header if it doesn't exist\n",
    "    output_file_path = os.path.join(output_dir, \"WingHeight.csv\")\n",
    "    header_written = os.path.exists(output_file_path)\n",
    "    with open(output_file_path, mode=\"a\", newline=\"\") as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=[\"Filename\", \"WingHeightInPixels\", \"WingHeightInMM\"])\n",
    "        if not header_written:\n",
    "            writer.writeheader()\n",
    "                    \n",
    "        # Loop through all jpg files\n",
    "        jpg_files = [file for file in os.listdir(input_dir) if file.endswith(\".jpg\")]\n",
    "        for filename in tqdm(jpg_files, desc=\"Processing files\", ncols=145):\n",
    "            input_path = input_dir / filename\n",
    "            output_path =  output_wing_dir / filename\n",
    "        \n",
    "            # Skip if output file exists\n",
    "            if os.path.exists(output_path):\n",
    "                continue   \n",
    "                \n",
    "            # Open the image\n",
    "            wing = Image.open(input_path)\n",
    "            wing = np.array(wing.convert(\"RGB\"))\n",
    "        \n",
    "            # Process the image\n",
    "            try:\n",
    "                wing = remove_background(wing)\n",
    "                cropped_image, height_pixels = crop_wing(wing)\n",
    "                \n",
    "            except Exception: \n",
    "                print(f\"\\tWarning: Image '{filename}' could not be processed.\")\n",
    "                continue\n",
    "            \n",
    "            # Flip left wings to the right\n",
    "            cropped_image = Image.fromarray(cropped_image)\n",
    "            if \"Left\" in filename:\n",
    "                cropped_image = cropped_image.transpose(method=Image.FLIP_LEFT_RIGHT)\n",
    "        \n",
    "            # Save the image and wing height\n",
    "            cropped_image.save(output_path)\n",
    "            height_mm = height_pixels / PIXELS_PER_MM\n",
    "            writer.writerow({\"Filename\": filename, \"WingHeightInPixels\": height_pixels, \"WingHeightInMM\": height_mm})\n",
    "\n",
    "# Handle exceptions\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc73d514-d175-428c-ba7a-17125ba258dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
