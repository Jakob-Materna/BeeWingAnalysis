{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08f93f0b-daf7-4efb-ada2-3fbb6c446cb3",
   "metadata": {},
   "source": [
    "### 2-1-LiveBeeLabelCropper.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1c8ba6c-04af-4011-b24b-73aa04ea122a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import shutil\n",
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1306ade7-9cbd-44df-a5e5-0fc6e76bc7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "data_dir = Path(\"/mnt/g/Projects/Master/Data/\")\n",
    "\n",
    "input_dir = data_dir / \"Raw\" / \"LiveBees\" \n",
    "output_dir = data_dir / \"Processed\" / \"LiveBees\" / \"1-LiveWingLabelCrops\" \n",
    "\n",
    "# select the segment anything model\n",
    "sam2_checkpoint = \"/home/wsl/bin/segment-anything-2/checkpoints/sam2_hiera_large.pt\"\n",
    "model_cfg = \"sam2_hiera_l.yaml\"\n",
    "\n",
    "DEBUG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de336f6e-92b6-424b-afcc-6ee18ade650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_white_area(image, y_coord, window_size, step_size, density_threshold):\n",
    "    h, w = image.shape\n",
    "    max_density = -1\n",
    "    best_coords = (0, 0)\n",
    "\n",
    "    # Start searching from the center x-coordinate\n",
    "    center_x = w // 2\n",
    "\n",
    "    # Radius-based search around the center x-coordinate\n",
    "    for radius in range(0, w // 2, step_size):\n",
    "        # Check positions to the left and right of the center within the current radius\n",
    "        for dx in range(-radius, radius + 1, step_size):\n",
    "            for direction in [-1, 1]:  # -1 for left, 1 for right\n",
    "                x = center_x + dx * direction\n",
    "\n",
    "                # Ensure the window is within bounds horizontally\n",
    "                if 0 <= x <= w - window_size and 0 <= y_coord <= h - window_size:\n",
    "                    # Extract a square window from the image\n",
    "                    window = image[y_coord:y_coord + window_size, x:x + window_size]\n",
    "\n",
    "                    # Count the number of white pixels\n",
    "                    white_pixel_count = np.sum(window >= 120)\n",
    "\n",
    "                    # Calculate density (fraction of white pixels in the window)\n",
    "                    density = white_pixel_count / (window_size * window_size)\n",
    "\n",
    "                    # Track the window with the maximum density of white pixels\n",
    "                    if density > max_density:\n",
    "                        max_density = density\n",
    "                        best_coords = (x, y_coord)\n",
    "\n",
    "                    # Early termination if a good enough density is found\n",
    "                    if density >= density_threshold:\n",
    "                        return best_coords\n",
    "\n",
    "    return best_coords\n",
    "    \n",
    "\n",
    "def identify_label(image, sampling_coords):\n",
    "    input_point = np.array(sampling_coords)\n",
    "    input_label = np.array([1] * len(sampling_coords))\n",
    "    \n",
    "    predictor.set_image(image)\n",
    "\n",
    "    masks, scores, _ = predictor.predict(\n",
    "    point_coords=input_point,\n",
    "    point_labels=input_label,\n",
    "    multimask_output=False,\n",
    "    )\n",
    "    mask = masks[0]\n",
    "\n",
    "    # Fill holes in the mask\n",
    "    mask = binary_fill_holes(mask).astype(int)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def crop_from_mask(mask, image):\n",
    "    # Identification of the label\n",
    "    # Convert mask to 8-bit single channel\n",
    "    mask = mask.astype(np.uint8)\n",
    "    \n",
    "    # Find contours\n",
    "    mask_contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Select the largest contour \n",
    "    mask_contour = max(mask_contours, key=cv2.contourArea)\n",
    "    \n",
    "    # Calculate the minimum area bounding box\n",
    "    mask_rect = cv2.minAreaRect(mask_contour)\n",
    "    \n",
    "    # Get the box points and convert them to integer coordinates\n",
    "    mask_box_points = cv2.boxPoints(mask_rect)\n",
    "    mask_box_points = np.intp(mask_box_points)\n",
    "\n",
    "    # Swap width and height if necessary to make the longer side horizontal\n",
    "    center, size, angle = mask_rect\n",
    "    if size[0] < size[1]:\n",
    "        angle += 90\n",
    "        size = (size[1], size[0])\n",
    "    \n",
    "    # Get the rotation matrix\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    \n",
    "    # Rotate the entire image to align the rectangle horizontally\n",
    "    height, width = mask.shape[:2]\n",
    "    rotated_image = cv2.warpAffine(image, rotation_matrix, (width, height), flags=cv2.INTER_LINEAR, borderValue=(255, 255, 255))\n",
    "\n",
    "    # Calculate the bounding box of the rotated rectangle in the rotated image\n",
    "    x, y, w, h = cv2.boundingRect(np.intp(cv2.transform(np.array([mask_box_points]), rotation_matrix))[0])\n",
    "\n",
    "    # Crop the aligned rectangle with white padding for any areas outside the original image\n",
    "    cropped_image = rotated_image[y:y+h, x:x+w]\n",
    "    \n",
    "    return mask_box_points, cropped_image\n",
    "\n",
    "    \n",
    "\n",
    "def crop_label(image, output_dir, jpg_file, coords=None):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.medianBlur(gray, 5)\n",
    "\n",
    "    # Take manually chosen coorinates or automaticly identify coorinates\n",
    "    if coords:\n",
    "        coords_list = coords\n",
    "    else:\n",
    "        label_coords = find_white_area(blurred, y_coord=1000, window_size=200, step_size=200, density_threshold=0.99)\n",
    "        modified_coord = (label_coords[0] + 100, label_coords[1] + 100)\n",
    "        coords_list = [label_coords, modified_coord]\n",
    "        \n",
    "    mask = identify_label(image, coords_list)\n",
    "    \n",
    "    mask_box_points, cropped_image = crop_from_mask(mask, image)\n",
    "\n",
    "    if DEBUG: \n",
    "        # Save cropped label\n",
    "        label_dir = output_dir / \"Labels\"\n",
    "        os.makedirs(label_dir, exist_ok=True)\n",
    "        label = Image.fromarray(cropped_image)\n",
    "        label.save(label_dir / jpg_file)\n",
    "\n",
    "        # Create an image directory\n",
    "        image_dir = output_dir / \"Process\"\n",
    "        os.makedirs(image_dir, exist_ok=True)\n",
    "        \n",
    "        # New 4 channel image (RGBA)\n",
    "        png_image = np.zeros((image.shape[0], image.shape[1], 4), dtype=np.uint8)\n",
    "        \n",
    "        # Apply the color to each channel (R, G, B)\n",
    "        for c in range(3):\n",
    "            png_image[:, :, c] = (mask * (1, 0, 0)[c] * 255).astype(np.uint8)\n",
    "        \n",
    "        # Set the alpha channel: 255 where the mask is present, 0 elsewhere\n",
    "        png_image[:, :, 3] = (mask * 255).astype(np.uint8)\n",
    "    \n",
    "        # Draw contours on the image for visualization\n",
    "        label_image = image.copy()\n",
    "        cv2.drawContours(label_image, [mask_box_points], 0, (255, 0, 0), 40)\n",
    "\n",
    "        # Create a 1x3 grid of images\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(30, 20))\n",
    "        # Show mask\n",
    "        x_coords, y_coords = zip(*coords_list)\n",
    "        axes[0].imshow(image)\n",
    "        axes[0].imshow(png_image, alpha=0.6)\n",
    "        axes[0].scatter(x_coords, y_coords, c=\"red\", s=20, edgecolor='black')\n",
    "        axes[0].axis(\"off\")\n",
    "        # Show rectangle\n",
    "        axes[1].imshow(label_image)\n",
    "        axes[1].axis(\"off\")\n",
    "        # Show cropped image  \n",
    "        axes[2].imshow(cropped_image)\n",
    "        axes[2].axis(\"off\")\n",
    "        plt.savefig(image_dir / jpg_file)\n",
    "        plt.close()\n",
    "    else:\n",
    "        # Save cropped label\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        label = Image.fromarray(cropped_image)\n",
    "        label.save(output_dir / jpg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c66df33-da95-40f6-911c-dc3a2a747a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# select the device for computation\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"using device: {device}\")\n",
    "\n",
    "# Select sam model\n",
    "sam2_model = build_sam2(model_cfg, sam2_checkpoint, device=device)\n",
    "predictor = SAM2ImagePredictor(sam2_model)\n",
    "\n",
    "# Color palette\n",
    "sns_colors = sns.color_palette(\"hls\", 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c01b5d0-be3c-434c-8ebf-47ad18dc9001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n",
      "WARNING: Output directory already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████████████████████████████████████████████████████████████████████████████████| 1194/1194 [03:41<00:00,  5.39it/s]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Ensure the input directory exists\n",
    "    if not os.path.exists(input_dir):\n",
    "        raise FileNotFoundError(f\"Input directory '{input_dir}' was not found.\")\n",
    "    \n",
    "    # Create the output directories\n",
    "    if os.path.exists(output_dir):\n",
    "        print(\"WARNING: Output directory already exists.\") \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Find all jpg files\n",
    "    jpg_files = []\n",
    "    for root, _, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".JPG\") or file.endswith(\".jpg\"):\n",
    "                jpg_files.append(os.path.join(root, file))\n",
    "    \n",
    "    # Loop through every file\n",
    "    for jpg_file_path in tqdm(jpg_files, desc=\"Processing files\", ncols=145):\n",
    "        jpg_basename = os.path.basename(jpg_file_path)\n",
    "        relative_jpg_path = str(jpg_file_path).removeprefix(str(input_dir)).lstrip(\"/\")\n",
    "        new_jpg_basename = relative_jpg_path.replace(\"/\", \"-\")\n",
    "        \n",
    "        # Skip if output file exists\n",
    "        if os.path.exists(output_dir / \"Labels\" / new_jpg_basename):\n",
    "            continue   \n",
    "            \n",
    "        # Process the file\n",
    "        image = cv2.imread(jpg_file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        crop_label(image, output_dir, new_jpg_basename)   \n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "# Handle exceptions\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ddf6014-80bd-4591-8ca6-b28592999aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directory for images with manual selected coordinates\n",
    "manual_dir = data_dir / \"Processed\" / \"LiveBees\" / \"2-LiveWingLabelCropsManuallyImproved\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "921a3526-6ae4-4003-a1b7-85c8749b46e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Output directory already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████████████████████████████████████████████████████████████████████████████████| 1194/1194 [00:32<00:00, 37.00it/s]\n"
     ]
    }
   ],
   "source": [
    "coords = {\"Round01-Hive01-2024_06_05-h01bee36\": ((4324, 1399), (4869, 1814)),\n",
    "          \"Round02-hive14-2024_06_20-h14b42\": ((3229, 889), (3559, 1304)),\n",
    "          \"Round02-hive14-2024_06_27-h14b23\": ((3064, 1079), (3374, 1304)),\n",
    "          \"Round02-hive14-2024_06_27-h14b30\": ((2999, 1194), (3359, 1324)),\n",
    "          \"Round04-hive34-2024_07_19-h34b25\": ((3124, 634), (3514, 919)),\n",
    "          \"Round04-hive35-2024_07_23-h35b27\": ((2809, 1034), (3339, 1409))}\n",
    "            \n",
    "try:\n",
    "    # Create the new output directories\n",
    "    if os.path.exists(manual_dir):\n",
    "        print(\"WARNING: Output directory already exists.\") \n",
    "    os.makedirs(manual_dir, exist_ok=True)\n",
    "    \n",
    "    # Find all jpg files\n",
    "    jpg_files = []\n",
    "    for root, _, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".JPG\") or file.endswith(\".jpg\"):\n",
    "                jpg_files.append(os.path.join(root, file))\n",
    "    \n",
    "    # Loop through every file\n",
    "    for jpg_file_path in tqdm(jpg_files, desc=\"Processing files\", ncols=145):\n",
    "        jpg_basename = os.path.basename(jpg_file_path)\n",
    "        relative_jpg_path = str(jpg_file_path).removeprefix(str(input_dir)).lstrip(\"/\")\n",
    "        new_jpg_basename = relative_jpg_path.replace(\"/\", \"-\")\n",
    "        \n",
    "        # Skip if output file exists\n",
    "        if os.path.exists(manual_dir / \"Labels\" / new_jpg_basename):\n",
    "            continue\n",
    "\n",
    "        if new_jpg_basename.removesuffix(\".JPG\") in coords.keys():\n",
    "            # Process the file using manual coordinates\n",
    "            coord = coords[new_jpg_basename.removesuffix(\".JPG\")]\n",
    "            image = cv2.imread(jpg_file_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            crop_label(image, manual_dir, new_jpg_basename, coord)   \n",
    "            cv2.destroyAllWindows()\n",
    "    \n",
    "        else:\n",
    "            # Copy the image\n",
    "            source_jpg = output_dir / \"Labels\" / new_jpg_basename\n",
    "            destination_jpg = manual_dir / \"Labels\" / new_jpg_basename\n",
    "            shutil.copy(source_jpg, destination_jpg)\n",
    "\n",
    "# Handle exceptions\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12be7b8-d3b7-4c8f-a401-36b3f6bf853b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
