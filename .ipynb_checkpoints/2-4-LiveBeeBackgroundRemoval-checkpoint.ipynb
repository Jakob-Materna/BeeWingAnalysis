{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc899be1-b186-46c4-b8bc-ec056d962e27",
   "metadata": {},
   "source": [
    "### 2-4-LiveBeeBackgroundRemoval.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fb8b4f8-fe7e-42d5-9934-097ba3002d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import glob\n",
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "from scipy.ndimage import label, sum as ndimage_sum\n",
    "\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "056d8a29-4a63-45d1-8589-064d8bdfc9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "data_dir = Path(\"/mnt/g/Projects/Master/Data/\")\n",
    "\n",
    "input_dir = data_dir / \"Processed\" / \"LiveBees\" / \"4-LiveWingCropsManuallyImproved\" \n",
    "output_dir = data_dir / \"Processed\" / \"LiveBees\" / \"5-LiveWingCropsRemovedBackground\" \n",
    "output_wing_dir = output_dir / \"Wings\"\n",
    "\n",
    "# Sam checkpoint path\n",
    "sam2_checkpoint = \"/home/wsl/bin/segment-anything-2/checkpoints/sam2_hiera_tiny.pt\"\n",
    "model_cfg = \"sam2_hiera_t.yaml\"\n",
    "\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d621ab28-68cc-4c4c-909f-76e5534b2cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_points_near_border(points, contour, border_dist_threshold):\n",
    "    \"\"\"\n",
    "    Filters out points too close to the edge of the wing to improve segment anything results.\n",
    "    \"\"\"\n",
    "    filtered_points = []\n",
    "\n",
    "    # Iterate over all points\n",
    "    for point in points:\n",
    "        # Check the distance of the point to the contour\n",
    "        dist_to_contour = cv2.pointPolygonTest(contour, (point[0], point[1]), True)\n",
    "        \n",
    "        # Keep the point if it's farther from the border than the threshold\n",
    "        if dist_to_contour >= border_dist_threshold:\n",
    "            filtered_points.append(point)\n",
    "    \n",
    "    return np.array(filtered_points)\n",
    "        \n",
    "\n",
    "def postprocess_mask(mask):\n",
    "    \"\"\"\n",
    "    Improves the output created by segment anything by selecting the best mask and filling holes.\n",
    "    \"\"\"\n",
    "    labeled_mask, num_features = label(mask)\n",
    "    if num_features == 0: \n",
    "        return mask\n",
    "    component_sizes = ndimage_sum(mask, labeled_mask, range(1, num_features + 1))\n",
    "    largest_component_label = np.argmax(component_sizes) + 1 \n",
    "    largest_component_mask = labeled_mask == largest_component_label\n",
    "\n",
    "    largest_component_mask = np.squeeze(largest_component_mask)\n",
    "    filled_image = binary_fill_holes(largest_component_mask)\n",
    "\n",
    "    clean_mask = binary_fill_holes(largest_component_mask)\n",
    "    if DEBUG:\n",
    "        # Display original and filled images\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "        axes[0].imshow(largest_component_mask, cmap=\"gray\")\n",
    "        axes[0].set_title(\"largest_component_mask\")\n",
    "        axes[0].axis(\"off\")\n",
    "        axes[1].imshow(clean_mask, cmap=\"gray\")\n",
    "        axes[1].set_title(\"clean_mask\")\n",
    "        axes[1].axis(\"off\")\n",
    "        plt.show()\n",
    "    return clean_mask\n",
    "\n",
    "\n",
    "def remove_background(wing, t=120):\n",
    "    \"\"\"\n",
    "    Uses segment anything to create a wing mask and removes everything outside the mask.\n",
    "    \"\"\"\n",
    "    expanded_image = wing\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(expanded_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply thresholding to get a binary image\n",
    "    _, thresh = cv2.threshold(gray, t, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Invert the binary image\n",
    "    inv_thresh = cv2.bitwise_not(thresh)\n",
    "    \n",
    "    # Find contour\n",
    "    contours, _ = cv2.findContours(inv_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    large_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > 5000]\n",
    "    \n",
    "    # Find the largest contour based on area\n",
    "    contour = max(large_contours, key=cv2.contourArea)\n",
    "    \n",
    "    # Draw contours on the image for visualization\n",
    "    wing_contour_image = expanded_image.copy()\n",
    "    cv2.drawContours(wing_contour_image, large_contours, -1, (0, 0, 255), 5)\n",
    "\n",
    "    if DEBUG:\n",
    "        # Show image\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.imshow(cv2.cvtColor(wing_contour_image, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    # Get bounding box of the contour\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    \n",
    "    # Create a dense grid of points within the bounding box\n",
    "    distance = 200  \n",
    "    height, width, channels = expanded_image.shape  \n",
    "    \n",
    "    # Create x and y coordinates\n",
    "    x_coords = np.arange(0, width, distance)\n",
    "    y_coords = np.arange(0, height, distance)\n",
    "    \n",
    "    # Create a meshgrid from the x and y coordinates\n",
    "    grid_x, grid_y = np.meshgrid(x_coords, y_coords)\n",
    "    \n",
    "    # Stack the x and y coordinates into a single array of points\n",
    "    grid_points = np.vstack([grid_x.ravel(), grid_y.ravel()]).T\n",
    "    \n",
    "    # Convert the NumPy array to a list of tuples with standard integers\n",
    "    grid_points = [(int(x), int(y)) for x, y in grid_points]\n",
    "    \n",
    "    inside_points = []\n",
    "    \n",
    "    # Check if points are inside the contour\n",
    "    for point in grid_points:\n",
    "        if cv2.pointPolygonTest(contour, (point[0], point[1]), False) >= 0:\n",
    "            inside_points.append(point)\n",
    "    \n",
    "    filtered_points = remove_points_near_border(inside_points, contour, 25)\n",
    "\n",
    "    if DEBUG:\n",
    "        # Plot the contour and the selected points\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.imshow(cv2.cvtColor(wing_contour_image, cv2.COLOR_BGR2RGB))\n",
    "        plt.scatter(filtered_points[:, 0], filtered_points[:, 1], c=\"red\", s=5)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    # Sam background removal\n",
    "    # Convert the points list to a numpy array\n",
    "    image_points = np.array(filtered_points)\n",
    "    image_labels = np.array([1] * len(filtered_points))\n",
    "    \n",
    "    predictor.set_image(expanded_image)\n",
    "    \n",
    "    mask, score, _ = predictor.predict(\n",
    "        point_coords=image_points,\n",
    "        point_labels=image_labels,\n",
    "        multimask_output=False,\n",
    "    )\n",
    "    sorted_ind = np.argsort(score)[::-1]\n",
    "    mask = mask[sorted_ind]\n",
    "    score = score[sorted_ind]\n",
    "\n",
    "    # Improve mask quality\n",
    "    mask = postprocess_mask(mask)\n",
    "    \n",
    "    # Remove extra dimension\n",
    "    mask = mask.squeeze()\n",
    "    \n",
    "    # Create a white image of the same size as the original image\n",
    "    white_image = np.ones_like(expanded_image) * 255\n",
    "    \n",
    "    # Apply the mask to each channel (no extra dimension added)\n",
    "    wing_image = np.where(mask[:, :, None], expanded_image, white_image)\n",
    "\n",
    "    if DEBUG:\n",
    "        # Show image\n",
    "        plt.figure(figsize=(20, 20))\n",
    "        plt.imshow(cv2.cvtColor(wing_image, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    return wing_image\n",
    "\n",
    "def crop_wing(wing_image):\n",
    "    \"\"\"\n",
    "    This main function finds an initial wing contour which is then improved with segment anything to remove the background. \n",
    "    \"\"\"\n",
    "    expanded_image = cv2.copyMakeBorder(wing_image, 1000, 1000, 1000, 1000, cv2.BORDER_CONSTANT, value=[255, 255, 255])\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(expanded_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply thresholding to get a binary image\n",
    "    _, thresh = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Invert the binary image\n",
    "    inv_thresh = cv2.bitwise_not(thresh)\n",
    "\n",
    "    # Find contour\n",
    "    contours, _ = cv2.findContours(inv_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    large_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > 5000]\n",
    "\n",
    "    # Find the largest contour based on area\n",
    "    contour = max(large_contours, key=cv2.contourArea)\n",
    "    \n",
    "    # Draw contours on the image for visualization\n",
    "    wing_contour_image = expanded_image.copy()\n",
    "    cv2.drawContours(wing_contour_image, large_contours, -1, (0, 0, 255), 5)\n",
    "\n",
    "    # Get the minimum area rectangle\n",
    "    rect = cv2.minAreaRect(contour)\n",
    "    \n",
    "    # Get the four points of the rectangle\n",
    "    box = cv2.boxPoints(rect)\n",
    "    \n",
    "    # Convert the points to integers\n",
    "    box = np.intp(box)\n",
    "    \n",
    "    # Draw the rotated rectangle\n",
    "    contour_image = expanded_image.copy()\n",
    "    cv2.drawContours(contour_image, [box], 0, (0, 0, 255), 5)\n",
    "    \n",
    "    # Get the rectangle's center, size (width, height), and angle\n",
    "    box_center, box_size, angle = rect\n",
    "    \n",
    "    # Ensure width is the longest side (width > height)\n",
    "    width, height = box_size\n",
    "    if height > width:\n",
    "        width, height = height, width\n",
    "        angle -= 90  # Rotate to make the longest side horizontal\n",
    "    \n",
    "    # Get the rotation matrix to rotate the image around the rectangle's center\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(box_center, angle, 1.0)\n",
    "    \n",
    "    # Rotate the entire image\n",
    "    rotated_image = cv2.warpAffine(expanded_image, rotation_matrix, (expanded_image.shape[1], expanded_image.shape[0]))\n",
    "    \n",
    "    # Convert the center and size to integers\n",
    "    box_center = (int(box_center[0]), int(box_center[1]))\n",
    "    width = int(width) \n",
    "    height = int(height)\n",
    "    \n",
    "    # Crop the aligned rectangle from the rotated image\n",
    "    cropped_image = cv2.getRectSubPix(rotated_image, (width+100, height+100), box_center)\n",
    "\n",
    "    return(cropped_image, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70088720-623b-4f19-b056-165ce0138dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████████████████████████████████████████████████████████████████████████████████| 1194/1194 [39:02<00:00,  1.96s/it]\n"
     ]
    }
   ],
   "source": [
    "# Ignore segment-anything warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# select the device for computation\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"using device: {device}\")\n",
    "\n",
    "# Load sam model\n",
    "sam2_model = build_sam2(model_cfg, sam2_checkpoint, device=device)\n",
    "predictor = SAM2ImagePredictor(sam2_model)\n",
    "\n",
    "try:\n",
    "    # Create the new output directories\n",
    "    if os.path.exists(output_wing_dir):\n",
    "        print(\"WARNING: Output directory already exists.\") \n",
    "    os.makedirs(output_wing_dir, exist_ok=True)\n",
    "\n",
    "    # Create or open a CSV file and write the header if it doesn't exist\n",
    "    output_file_path = os.path.join(output_dir, \"WingHeight.csv\")\n",
    "    header_written = os.path.exists(output_file_path)\n",
    "    with open(output_file_path, mode=\"a\", newline=\"\") as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=[\"Filename\", \"WingHeightInPixels\"])\n",
    "        if not header_written:\n",
    "            writer.writeheader()\n",
    "\n",
    "        # Process every jpg file\n",
    "        jpg_files = list(input_dir.glob(\"*.JPG\"))\n",
    "        for jpg_file in tqdm(jpg_files, desc=\"Processing files\", ncols=145):\n",
    "            increase_tresh = False\n",
    "            filename = jpg_file.name\n",
    "            output_file = output_wing_dir / filename\n",
    "        \n",
    "            # Skip if the file exists\n",
    "            if os.path.exists(output_file):\n",
    "                continue\n",
    "    \n",
    "            # Open the image\n",
    "            wing = Image.open(jpg_file)\n",
    "            wing = np.array(wing.convert(\"RGB\"))\n",
    "            brightness = np.mean(wing)\n",
    "            # print(f\"brightness: {brightness}\")\n",
    "            if brightness > 180:\n",
    "                increase_tresh = True\n",
    "            else:\n",
    "                try:    \n",
    "                    new_wing = remove_background(wing, 120)\n",
    "                    cropped_image, height_pixels = crop_wing(new_wing)\n",
    "                    # print(f\"height_pixels: {height_pixels}\")\n",
    "                except (IndexError, ValueError):\n",
    "                    increase_tresh = True\n",
    "            if height_pixels < 200 or increase_tresh:\n",
    "                wing = Image.open(jpg_file)\n",
    "                wing = np.array(wing.convert(\"RGB\"))\n",
    "                new_wing = remove_background(wing, 200)\n",
    "                cropped_image, height_pixels = crop_wing(new_wing)\n",
    "                \n",
    "            # Save the image and wing height\n",
    "            cropped_image = Image.fromarray(cropped_image)\n",
    "            cropped_image.save(output_file)\n",
    "            writer.writerow({\"Filename\": filename, \"WingHeightInPixels\": height_pixels})\n",
    "        \n",
    "# Handle exceptions\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c203553-d281-4950-b65f-fd6c2725ae8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
